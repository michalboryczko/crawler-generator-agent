# Example Output

This directory contains example outputs generated by the Crawler Agent.

## Structure

```
examples/
└── example_one/
    ├── plan.md              # Generated crawl plan
    └── extras/              # Reference documentation for implementation
        ├── headfull-chrome.md
        ├── crawler-blueprint.md
        ├── logging-standards.md
        └── python-tips.md
```

## plan.md

The main output file containing the complete crawl plan with:

- **Site Analysis** — Discovered page structure and content patterns
- **CSS Selectors** — Validated selectors for listings and articles
- **Pagination Strategy** — Detected pagination type and navigation rules
- **Extraction Rules** — Field mappings for content extraction
- **Test Dataset Reference** — Sample data for validation

### Example Plan Output

```markdown
# Crawl Plan: example.com/blog

## Site Overview
- **Base URL**: https://example.com/blog
- **Pagination Type**: numbered
- **Max Pages**: 10
- **HTTP Accessible**: Yes (no JavaScript required)

## Listing Page Selectors
| Field | Selector | Confidence |
|-------|----------|------------|
| Article Link | `article.post h2 a` | 95% |
| Title | `article.post h2` | 95% |
| Summary | `article.post .excerpt` | 90% |

## Article Page Selectors
| Field | Selector | Confidence |
|-------|----------|------------|
| Title | `h1.article-title` | 98% |
| Content | `div.article-body` | 95% |
| Author | `span.author-name` | 85% |
| Date | `time.published` | 90% |

## Pagination
- **Pattern**: `?page={n}`
- **Next Button**: `a.pagination-next`
- **Max Pages Detected**: 10
```

## extras/

The `extras/` directory contains **reference documentation** designed to be passed as context to AI coding assistants (like Claude Code, Cursor, or GitHub Copilot) during crawler implementation.

### Purpose

When implementing a production crawler based on the generated plan, these extras provide:

- **API Documentation** — Reference docs for browser automation services
- **Architecture Blueprints** — Recommended patterns and code structure
- **Coding Standards** — Project-specific conventions and best practices
- **Implementation Tips** — Language-specific guidance and common pitfalls

### Usage with AI Coding Assistants

Pass extras as context when asking AI assistants to implement the crawler:

```bash
# Example: Using with Claude Code
claude "Implement a crawler based on plan.md using the patterns in extras/"

# Example: Copy to clipboard for other assistants
cat examples/example_one/extras/*.md | pbcopy
```

### Available Extras

| File | Description |
|------|-------------|
| `headfull-chrome.md` | Headfull Chrome API reference for browser automation |
| `crawler-blueprint.md` | Recommended crawler architecture and patterns |
| `logging-standards.md` | Structured logging conventions |
| `python-tips.md` | Python-specific implementation guidance |

## Generating Your Own Examples

Run the crawler agent on a target site:

```bash
python main.py https://example.com/blog
```

Output will be generated in `plans_output/<site_name>/`.
