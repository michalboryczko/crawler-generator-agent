"""Orchestration tools for coordinating agents."""
import logging
from typing import Any

from .base import BaseTool

logger = logging.getLogger(__name__)


class RunBrowserAgentTool(BaseTool):
    """Run the Browser Agent to analyze a webpage."""

    name = "run_browser_agent"
    description = """Run the Browser Agent to navigate to a URL and extract article links.
    The agent will store results in shared memory."""

    def __init__(self, browser_agent):
        self.browser_agent = browser_agent

    def execute(self, task: str) -> dict[str, Any]:
        try:
            result = self.browser_agent.run(task)
            return {
                "success": result["success"],
                "result": result.get("result", result.get("error")),
                "iterations": result.get("iterations", 0)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_parameters_schema(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "task": {
                    "type": "string",
                    "description": "Task description for the browser agent"
                }
            },
            "required": ["task"]
        }


class RunSelectorAgentTool(BaseTool):
    """Run the Selector Agent to find CSS selectors."""

    name = "run_selector_agent"
    description = """Run the Selector Agent to find and verify CSS selectors.
    The agent reads extracted articles from memory and stores final selectors."""

    def __init__(self, selector_agent):
        self.selector_agent = selector_agent

    def execute(self, task: str) -> dict[str, Any]:
        try:
            result = self.selector_agent.run(task)
            return {
                "success": result["success"],
                "result": result.get("result", result.get("error")),
                "iterations": result.get("iterations", 0)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_parameters_schema(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "task": {
                    "type": "string",
                    "description": "Task description for the selector agent"
                }
            },
            "required": ["task"]
        }


class GenerateCrawlPlanTool(BaseTool):
    """Generate the final crawl plan as markdown."""

    name = "generate_crawl_plan"
    description = "Generate a markdown crawl plan from the collected data in memory."

    def __init__(self, memory_store):
        self.memory_store = memory_store

    def execute(self) -> dict[str, Any]:
        try:
            target_url = self.memory_store.read("target_url") or "Unknown"
            article_selector = self.memory_store.read("article_selector") or "Not found"
            article_confidence = self.memory_store.read("article_selector_confidence") or 0
            pagination_selector = self.memory_store.read("pagination_selector")
            pagination_type = self.memory_store.read("pagination_type")
            extracted_articles = self.memory_store.read("extracted_articles") or []

            plan = f"""# Web Crawler Plan

## Target Site
- **URL**: {target_url}
- **Generated**: Auto-generated by Crawler Agent

## Article Extraction

### Selector
```css
{article_selector}
```

### Confidence
- Score: {article_confidence}
- Sample articles found: {len(extracted_articles)}

### Sample Articles
"""
            for i, article in enumerate(extracted_articles[:5]):
                if isinstance(article, dict):
                    plan += f"- {article.get('text', 'No title')}: {article.get('href', 'No URL')}\n"
                else:
                    plan += f"- {article}\n"

            plan += "\n## Pagination\n"
            if pagination_selector:
                plan += f"""
### Type: {pagination_type or 'Unknown'}

### Selector
```css
{pagination_selector}
```

### Strategy
"""
                if pagination_type == "next_button":
                    plan += "- Click the next button until no more pages\n"
                elif pagination_type == "numbered":
                    plan += "- Iterate through numbered page links\n"
                elif pagination_type == "infinite_scroll":
                    plan += "- Scroll to bottom to load more content\n"
            else:
                plan += "No pagination detected - single page of articles.\n"

            plan += """
## Crawler Configuration

```python
config = {
    "start_url": "%s",
    "article_selector": "%s",
    "pagination": {
        "enabled": %s,
        "selector": %s,
        "type": "%s"
    },
    "wait_between_requests": 2,
    "max_pages": 10
}
```
""" % (
    target_url,
    article_selector,
    str(pagination_selector is not None).lower(),
    f'"{pagination_selector}"' if pagination_selector else "null",
    pagination_type or "none"
)

            return {
                "success": True,
                "result": plan
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def get_parameters_schema(self) -> dict[str, Any]:
        return {"type": "object", "properties": {}}
